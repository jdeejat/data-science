{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2 - Exploring Hacker News Posts\n",
    "\n",
    "Data source is [Hacker News Posts on kaggle](https://www.kaggle.com/hacker-news/hacker-news-posts).\n",
    "\n",
    "Below are descriptions of the columns:\n",
    "\n",
    "- id: The unique identifier from Hacker News for the post\n",
    "- title: The title of the post\n",
    "- url: The URL that the posts links to, if the post has a URL\n",
    "- num_points: The number of points the post acquired, calculated as the total number of upvotes minus the total number of downvotes\n",
    "- num_comments: The number of comments that were made on the post\n",
    "- author: The username of the person who submitted the post\n",
    "- created_at: The date and time at which the post was submitted\n",
    "\n",
    "We're specifically interested in posts whose titles begin with either *Ask HN* or *Show HN*. Users submit Ask HN posts to ask the Hacker News community a specific question. Likewise, users submit Show HN posts to show the Hacker News community a project, product, or just generally something interesting. \n",
    "\n",
    "We'll start with comparing these two types of posts to determine the following:\n",
    "\n",
    "- Do Ask HN or Show HN receive more comments on average?\n",
    "- Do posts created at a certain time receive more comments on average?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Importing Data\n",
    "\n",
    "Let's start with importing data using Pandas just to see how data looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>num_points</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>author</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12579008</td>\n",
       "      <td>You have two days to comment if you want stem ...</td>\n",
       "      <td>http://www.regulations.gov/document?D=FDA-2015...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>altstar</td>\n",
       "      <td>9/26/2016 3:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12579005</td>\n",
       "      <td>SQLAR  the SQLite Archiver</td>\n",
       "      <td>https://www.sqlite.org/sqlar/doc/trunk/README.md</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>blacksqr</td>\n",
       "      <td>9/26/2016 3:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12578997</td>\n",
       "      <td>What if we just printed a flatscreen televisio...</td>\n",
       "      <td>https://medium.com/vanmoof/our-secrets-out-f21...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>pavel_lishin</td>\n",
       "      <td>9/26/2016 3:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12578989</td>\n",
       "      <td>algorithmic music</td>\n",
       "      <td>http://cacm.acm.org/magazines/2011/7/109891-al...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>poindontcare</td>\n",
       "      <td>9/26/2016 3:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12578979</td>\n",
       "      <td>How the Data Vault Enables the Next-Gen Data W...</td>\n",
       "      <td>https://www.talend.com/blog/2016/05/12/talend-...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>markgainor1</td>\n",
       "      <td>9/26/2016 3:14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                              title  \\\n",
       "0  12579008  You have two days to comment if you want stem ...   \n",
       "1  12579005                         SQLAR  the SQLite Archiver   \n",
       "2  12578997  What if we just printed a flatscreen televisio...   \n",
       "3  12578989                                  algorithmic music   \n",
       "4  12578979  How the Data Vault Enables the Next-Gen Data W...   \n",
       "\n",
       "                                                 url  num_points  \\\n",
       "0  http://www.regulations.gov/document?D=FDA-2015...           1   \n",
       "1   https://www.sqlite.org/sqlar/doc/trunk/README.md           1   \n",
       "2  https://medium.com/vanmoof/our-secrets-out-f21...           1   \n",
       "3  http://cacm.acm.org/magazines/2011/7/109891-al...           1   \n",
       "4  https://www.talend.com/blog/2016/05/12/talend-...           1   \n",
       "\n",
       "   num_comments        author      created_at  \n",
       "0             0       altstar  9/26/2016 3:26  \n",
       "1             0      blacksqr  9/26/2016 3:24  \n",
       "2             0  pavel_lishin  9/26/2016 3:19  \n",
       "3             0  poindontcare  9/26/2016 3:16  \n",
       "4             0   markgainor1  9/26/2016 3:14  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"HN_posts_year_to_Sep_26_2016.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rest of the project will be compleated without additial libriries. We will be working with data in list of list format.\n",
    "\n",
    "Let's:\n",
    "- open and read data \n",
    "- import data as list of lists\n",
    "- remove headers \n",
    "- assign dataset to 'hn' variable\n",
    "- look at first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['12579008',\n",
       "  'You have two days to comment if you want stem cells to be classified as your own',\n",
       "  'http://www.regulations.gov/document?D=FDA-2015-D-3719-0018',\n",
       "  '1',\n",
       "  '0',\n",
       "  'altstar',\n",
       "  '9/26/2016 3:26'],\n",
       " ['12579005',\n",
       "  'SQLAR  the SQLite Archiver',\n",
       "  'https://www.sqlite.org/sqlar/doc/trunk/README.md',\n",
       "  '1',\n",
       "  '0',\n",
       "  'blacksqr',\n",
       "  '9/26/2016 3:24'],\n",
       " ['12578997',\n",
       "  'What if we just printed a flatscreen television on the side of our boxes?',\n",
       "  'https://medium.com/vanmoof/our-secrets-out-f21c1f03fdc8#.ietxmez43',\n",
       "  '1',\n",
       "  '0',\n",
       "  'pavel_lishin',\n",
       "  '9/26/2016 3:19'],\n",
       " ['12578989',\n",
       "  'algorithmic music',\n",
       "  'http://cacm.acm.org/magazines/2011/7/109891-algorithmic-composition/fulltext',\n",
       "  '1',\n",
       "  '0',\n",
       "  'poindontcare',\n",
       "  '9/26/2016 3:16'],\n",
       " ['12578979',\n",
       "  'How the Data Vault Enables the Next-Gen Data Warehouse and Data Lake',\n",
       "  'https://www.talend.com/blog/2016/05/12/talend-and-Â\\x93the-data-vaultÂ\\x94',\n",
       "  '1',\n",
       "  '0',\n",
       "  'markgainor1',\n",
       "  '9/26/2016 3:14']]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from csv import reader\n",
    "open_file = open(\"HN_posts_year_to_Sep_26_2016.csv\")\n",
    "read_file = reader(open_file)\n",
    "hn = list(read_file)\n",
    "hn = hn[1:]\n",
    "hn[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Clean Data\n",
    "\n",
    "## 2.2 Slice data\n",
    "Since we're only concerned with post titles beginning with Ask HN or Show HN, we'll create new lists of lists containing just the data for those titles.\n",
    "\n",
    "To find the posts that begin with either Ask HN or Show HN, we'll use the string method startswith. To control for case, we can use the lower method which returns a lowercase version of the starting string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9139\n",
      "10158\n",
      "273822\n"
     ]
    }
   ],
   "source": [
    "# Identify posts that begin with either `Ask HN` or `Show HN` and separate the data into different lists.\n",
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "\n",
    "for row in hn:\n",
    "    title = row[1]\n",
    "    title_low = title.lower()\n",
    "    if title_low.startswith('ask hn') == True:\n",
    "        ask_posts.append(row)\n",
    "    elif title_low.startswith('show hn') == True:\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "        \n",
    "print(len(ask_posts))\n",
    "print(len(show_posts))\n",
    "print(len(other_posts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 - Analyze Data \n",
    "\n",
    "## 3.1 Determine if ask posts or show posts receive more comments on average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.393478498741656\n",
      "4.886099625910612\n"
     ]
    }
   ],
   "source": [
    "total_ask_comments = 0\n",
    "total_show_comments = 0\n",
    "\n",
    "for row in ask_posts:\n",
    "    comment = int(row[4])\n",
    "    total_ask_comments += comment\n",
    "    \n",
    "for row in show_posts:\n",
    "    comment = int(row[4])\n",
    "    total_show_comments += comment\n",
    "\n",
    "avg_ask_comments = total_ask_comments / len(ask_posts)\n",
    "avg_show_comments = total_show_comments / len(show_posts)\n",
    "\n",
    "print(avg_ask_comments)\n",
    "print(avg_show_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On Average ask comments get 10 comments vs show comments get only 4 comments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Determine if ask posts created at a certain time are more likely to attract comments\n",
    "\n",
    "We'll use the following steps to perform this analysis:\n",
    "\n",
    "1. Calculate the amount of ask posts created in each hour of the day, along with the number of comments received.\n",
    "2. Calculate the average number of comments ask posts receive by hour created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'02': 2996,\n",
       " '01': 2089,\n",
       " '22': 3372,\n",
       " '21': 4500,\n",
       " '19': 3954,\n",
       " '17': 5547,\n",
       " '15': 18525,\n",
       " '14': 4972,\n",
       " '13': 7245,\n",
       " '11': 2797,\n",
       " '10': 3013,\n",
       " '09': 1477,\n",
       " '07': 1585,\n",
       " '03': 2154,\n",
       " '23': 2297,\n",
       " '20': 4462,\n",
       " '16': 4466,\n",
       " '08': 2362,\n",
       " '00': 2277,\n",
       " '18': 4877,\n",
       " '12': 4234,\n",
       " '04': 2360,\n",
       " '06': 1587,\n",
       " '05': 1838}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#STEP 1\n",
    "# import datetime module\n",
    "import datetime as dt\n",
    "date_format = \"%m/%d/%Y %H:%M\"\n",
    "\n",
    "\n",
    "#create empty lists and dict\n",
    "result_list = []\n",
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "\n",
    "#extract data into separate list \n",
    "for row in ask_posts:\n",
    "    result_list.append(\n",
    "        [row[6], int(row[4])]\n",
    "    )\n",
    "\n",
    "#populate dict with data from result_list\n",
    "\n",
    "for each_row in result_list:\n",
    "    date = each_row[0]\n",
    "    comment = each_row[1]\n",
    "    #datetime example of parce and format at the same time\n",
    "    time = dt.datetime.strptime(date, date_format).strftime(\"%H\")\n",
    "    if time in counts_by_hour:\n",
    "        comments_by_hour[time] += comment\n",
    "        counts_by_hour[time] += 1\n",
    "    else:\n",
    "        comments_by_hour[time] = comment\n",
    "        counts_by_hour[time] = 1\n",
    "\n",
    "comments_by_hour\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['02', 11.137546468401487],\n",
       " ['01', 7.407801418439717],\n",
       " ['22', 8.804177545691905],\n",
       " ['21', 8.687258687258687],\n",
       " ['19', 7.163043478260869],\n",
       " ['17', 9.449744463373083],\n",
       " ['15', 28.676470588235293],\n",
       " ['14', 9.692007797270955],\n",
       " ['13', 16.31756756756757],\n",
       " ['11', 8.96474358974359],\n",
       " ['10', 10.684397163120567],\n",
       " ['09', 6.653153153153153],\n",
       " ['07', 7.013274336283186],\n",
       " ['03', 7.948339483394834],\n",
       " ['23', 6.696793002915452],\n",
       " ['20', 8.749019607843136],\n",
       " ['16', 7.713298791018998],\n",
       " ['08', 9.190661478599221],\n",
       " ['00', 7.5647840531561465],\n",
       " ['18', 7.94299674267101],\n",
       " ['12', 12.380116959064328],\n",
       " ['04', 9.7119341563786],\n",
       " ['06', 6.782051282051282],\n",
       " ['05', 8.794258373205741]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#STEP 2\n",
    "#we will use two dict above to create list of list with average data\n",
    "avg_by_hour = []\n",
    "\n",
    "for hour in comments_by_hour:\n",
    "    avg_by_hour.append([hour, comments_by_hour[hour]/counts_by_hour[hour]])\n",
    "    \n",
    "avg_by_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we now have the results we need, this format makes it hard to identify the hours with the highest values. Let's finish by sorting the list of lists and printing the five highest values in a format that's easier to read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11.137546468401487, '02'], [7.407801418439717, '01'], [8.804177545691905, '22'], [8.687258687258687, '21'], [7.163043478260869, '19'], [9.449744463373083, '17'], [28.676470588235293, '15'], [9.692007797270955, '14'], [16.31756756756757, '13'], [8.96474358974359, '11'], [10.684397163120567, '10'], [6.653153153153153, '09'], [7.013274336283186, '07'], [7.948339483394834, '03'], [6.696793002915452, '23'], [8.749019607843136, '20'], [7.713298791018998, '16'], [9.190661478599221, '08'], [7.5647840531561465, '00'], [7.94299674267101, '18'], [12.380116959064328, '12'], [9.7119341563786, '04'], [6.782051282051282, '06'], [8.794258373205741, '05']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[28.676470588235293, '15'],\n",
       " [16.31756756756757, '13'],\n",
       " [12.380116959064328, '12'],\n",
       " [11.137546468401487, '02'],\n",
       " [10.684397163120567, '10'],\n",
       " [9.7119341563786, '04'],\n",
       " [9.692007797270955, '14'],\n",
       " [9.449744463373083, '17'],\n",
       " [9.190661478599221, '08'],\n",
       " [8.96474358974359, '11'],\n",
       " [8.804177545691905, '22'],\n",
       " [8.794258373205741, '05'],\n",
       " [8.749019607843136, '20'],\n",
       " [8.687258687258687, '21'],\n",
       " [7.948339483394834, '03'],\n",
       " [7.94299674267101, '18'],\n",
       " [7.713298791018998, '16'],\n",
       " [7.5647840531561465, '00'],\n",
       " [7.407801418439717, '01'],\n",
       " [7.163043478260869, '19'],\n",
       " [7.013274336283186, '07'],\n",
       " [6.782051282051282, '06'],\n",
       " [6.696793002915452, '23'],\n",
       " [6.653153153153153, '09']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sort the values from list above by top hours with avg comments\n",
    "#Use the sorted() function\n",
    "swap_avg_by_hour = []\n",
    "\n",
    "for row in avg_by_hour:\n",
    "    swap_avg_by_hour.append([row[1], row[0]])\n",
    "    \n",
    "print(swap_avg_by_hour)\n",
    "\n",
    "sorted_swap = sorted(swap_avg_by_hour, reverse=True)\n",
    "\n",
    "sorted_swap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for 'Ask HN' Comments\n",
      "15:00: 28.68 average comments per post\n",
      "13:00: 16.32 average comments per post\n",
      "12:00: 12.38 average comments per post\n",
      "02:00: 11.14 average comments per post\n",
      "10:00: 10.68 average comments per post\n"
     ]
    }
   ],
   "source": [
    "#print the the 5 hours with the highest average comments\n",
    "#Use the str.format() method \n",
    "\n",
    "print(\"Top 5 Hours for 'Ask HN' Comments\")\n",
    "\n",
    "for avg, hr in sorted_swap[:5]:\n",
    "    print(\n",
    "        \"{hour}: {average:.2f} average comments per post\".format(\n",
    "            hour=dt.datetime.strptime(hr, \"%H\").strftime(\"%H:%M\"),\n",
    "            average=avg\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hour that receives the most comments per post on average is 15:00, with an average of 28.68 comments per post. \n",
    "\n",
    "According to the data set [documentation](https://www.kaggle.com/hacker-news/hacker-news-posts/home), the timezone used is Eastern Time in the US."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "In this project, we analyzed ask posts and show posts to determine which type of post and time receive the most comments on average. Based on our analysis, to maximize the amount of comments a post receives, we'd recommend the post be categorized as ask post and created between 15:00 and 16:00 (3:00 pm est - 4:00 pm est)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
