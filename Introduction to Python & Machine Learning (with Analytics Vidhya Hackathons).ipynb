{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Python & Machine Learning (with Analytics Vidhya Hackathons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1 - Introduction to Python for Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why learn Python for data analysis?\n",
    "\n",
    "Python (an interpreted language) has gathered a lot of interest recently as a preferred choice of language for data analysis. Here are some reasons in favour of learning Python:\n",
    "\n",
    "It is open source – free to install and use\n",
    "Python has an awesome online community - latest algorithms come to Python in a matter of days\n",
    "It is easy to learn\n",
    "It can become a common language for data science and production of web-based analytics products\n",
    "Which of the following is not a reason to learn Python for data analysis?\n",
    "\n",
    "## Python 2.7 vs. Python 3.5?\n",
    "\n",
    "You will come across this question soon after you start using Python. Python has 2 popular competing versions. Both versions have their pros and cons.\n",
    "\n",
    "Benefits of Python 2.7\n",
    "\n",
    "Awesome online community. Easier to find answers when you get stuck at places.\n",
    "Tonnes of third party libraries\n",
    "Benefits of Python 3.5\n",
    "\n",
    "Cleaner and faster\n",
    "It is the future!\n",
    "You can read a more detailed answer [here](http://discuss.analyticsvidhya.com/t/python-2-7-or-3-5-which-one-to-choose-for-data-science/7151)\n",
    "\n",
    "Which version of Python would you recommend to someone who needs to use several third party libraries?\n",
    "\n",
    "## Python installation\n",
    "\n",
    "While DataCamp provides an awesome interface to get you started, you will need to run a local instance of Python for any serious Data Science work. The simplest way would be to download Anaconda. An open source distribution of Python, it has most of the libraries & packages you would need, and removes any version conflicts. I strongly recommend this for beginners. For this course, we will be using Python 3.x\n",
    "\n",
    "Should you install a local instance of Python on your machine to continue this course?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2 - Python Libraries and data structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a List\n",
    "\n",
    "Lists are probably the most versatile data structures in Python. A list can be defined by writing a list of comma separated values in square brackets. Lists might contain items of different types. Python lists are mutable - individual elements of a list can be changed while the identity does not change.\n",
    "\n",
    "Country =['INDIA','USA','GERMANY','UK','AUSTRALIA']\n",
    "\n",
    "Temperature =[44, 28, 20, 18, 25, 45, 67]\n",
    "\n",
    "We just created two lists, one for Country names (strings) and another one for Temperature data (whole numbers).\n",
    "\n",
    "Accessing individual elements of a list\n",
    "Individual elements of a list can be accessed by writing an index number in square bracket. The first index of a list starts with 0 (zero) not 1. For example, Country[0] can be used to access the first element, 'INDIA'\n",
    "A range of elements can be accessed by using start index and end index but it does not return the value of the end index. For example, Temperature[1:4] returns three elements, the second through fourth elements [28, 20, 18], but not the fifth element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[1, 4, 9]\n"
     ]
    }
   ],
   "source": [
    "# Create a list of squared numbers\n",
    "squares_list = [0, 1, 4, 9, 16, 25]\n",
    "\n",
    "# Now write a line of code to create a list of the first five odd numbers and store it in a variable odd_numbers\n",
    "odd_numbers= [1, 3, 5, 7, 9]\n",
    "\n",
    "# Print the first element of squares_list\n",
    "print (squares_list[0])\n",
    "\n",
    "# Print the second to fourth elements of squares_list\n",
    "print(squares_list[1:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a String\n",
    "\n",
    "Strings can simply be defined by use of single ( ‘ ), double ( ” ) or triple ( ”’ ) inverted commas. Strings enclosed in triple quotes ( ”’ ) can span over multiple lines. A few things to keep in mind about strings:\n",
    "\n",
    "Strings are immutable in Python, so you can not change the content of a string.\n",
    "Function len() can be used to get length of a string\n",
    "You can access the elements using indexes as you do for lists\n",
    "String =\"String elements can also be accessed using index numbers, just like lists\"\n",
    "\n",
    "~~~\n",
    "print (String[0:7])\n",
    "~~~\n",
    "\n",
    "#Above print command displays \"String \" on screen.\n",
    "You can use '+' operator to concatenate two strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "awesome!\n",
      "I am doing a course Introduction to Hackathon using Python\n"
     ]
    }
   ],
   "source": [
    "# Create a string str1\n",
    "str1 = \"Introduction with strings\"\n",
    "\n",
    "# Now store the length of string str1 in variable str_len\n",
    "str_len = len(str1)\n",
    "print(str_len)\n",
    "str_new = \"Machine Learning is awesome!\"\n",
    "# Print last eight characters of string str_new (the length of str_new is 28 characters).\n",
    "print (str_new[20:28])\n",
    "\n",
    "str2 = \"I am doing a course Introduction to Hackathon using \"\n",
    "str3 = \"Python\"\n",
    "\n",
    "# Write a line of code to store concatenated string of str2 and str3 into variable str4\n",
    "str4 = str2 + str3\n",
    "print(str4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Dictionary\n",
    "\n",
    "A Dictionary is an unordered set of key:value pairs, with the requirement that the keys are unique (within a Dictionary). A few pointers about dictionary:\n",
    "\n",
    "An empty dictionary can be created by a pair of braces: {}.\n",
    "Dictionary elements can be accessed by dictionary keys\n",
    "DICT.keys() will return all the keys of given dictionary \"DICT\"\n",
    "~~~\n",
    "DICT = {\n",
    "  'Name':'Kunal',\n",
    "  'Company':'Analytics Vidhya'\n",
    "  }\n",
    "~~~\n",
    "#Dictionary elements can be accessed by keys\n",
    "\n",
    "~~~\n",
    "print (DICT['Name'])\n",
    "~~~\n",
    "\n",
    "#The above print statement will print Kunal\n",
    "\n",
    "In dictionary \"DICT\", Name and Company are dictionary keys whereas \"Kunal\" and \"Analytics Vidhya\" are their respective values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "dict_keys(['Age', 'Name', 'Sports'])\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary dict1\n",
    "dict1 = { 'Age': 16, 'Name': 'Max', 'Sports': 'Cricket'}\n",
    "\n",
    "# Update the value of Age to 18\n",
    "dict1['Age'] = 18\n",
    "\n",
    "# Print the value of Age\n",
    "print (dict1['Age'])\n",
    "\n",
    "# Store the keys of dictionary dict1 to dict_keys\n",
    "dict_keys = dict1.keys()\n",
    "print(dict_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use Python libraries?\n",
    "\n",
    "First of all - great progress! You now know some of the important data structures in Python.\n",
    "\n",
    "Let's take another step ahead in our journey to learn Python, by getting acquainted with some useful libraries. The first step is to learn to import them into your environment. There are several ways of doing so in Python:\n",
    "\n",
    "~~~\n",
    "import math as m\n",
    "\n",
    "from math import *\n",
    "~~~\n",
    "\n",
    "In the first manner, we have defined an alias m to library math. We can now use various functions from math library (e.g. factorial) by referencing it using the alias m.factorial().\n",
    "\n",
    "In the second manner, you have imported the entire name space in math i.e. you can directly use factorial() without referring to math.\n",
    "\n",
    "Following are a list of libraries, you will need for any scientific computations and data analysis:\n",
    "\n",
    "- Numpy\n",
    "- Scipy\n",
    "- Pandas\n",
    "- Matplotlib\n",
    "- Scikit Learn\n",
    "\n",
    "Which of the following is a valid import statement for below code?\n",
    "~~~print (factorial(5))~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why are conditional statements required?\n",
    "\n",
    "Conditional statements are used to execute code fragments based on a given condition. The most commonly used construct is if-else, with the following syntax:\n",
    "\n",
    "~~~\n",
    "if [condition]:\n",
    "  __execution if true__\n",
    "else:\n",
    "  __execution if false__\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "6\n",
      "Greater than 5\n"
     ]
    }
   ],
   "source": [
    "# Create a two integer variables a and b\n",
    "a=3\n",
    "b=4\n",
    "\n",
    "# if a is greater than b print a-b else a+b\n",
    "if a > b:\n",
    "    print (a-b)\n",
    "else:\n",
    "    print (a+b)\n",
    "\n",
    "# Create a list of squared numbers\n",
    "squares_list = [0, 1, 4, 9, 16, 25]\n",
    "\n",
    "# Store the length of squares_list in square_len\n",
    "square_len = len(squares_list)\n",
    "print(square_len)\n",
    "\n",
    "# if square_len is less than 5 then print \"Less than 5\" else \"Greater than 5\"\n",
    "if square_len < 5:\n",
    "    print (\"Less than 5\")\n",
    "else:\n",
    "    print (\"Greater than 5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How iterative statements help?\n",
    "\n",
    "Computers are often used to automate repetitive tasks. Repeating identical or similar tasks without making errors is something that computers do well. Repeated execution of a set of statements is called iteration.\n",
    "\n",
    "Like most languages, Python also has a FOR-loop which is the most widely used method for iteration. It has a simple syntax:\n",
    "\n",
    "```\n",
    "for i in [Python Iterable]:\n",
    "  expression(i)\n",
    "```\n",
    "\n",
    "“Python Iterable” can be a list or other advanced data structures which we will explore in later sections. Let’s take a look at a simple example, determining the factorial of a number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4]\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "# this declares eampty list 'ls' and appends x first 5 numbers\n",
    "ls=[]\n",
    "for x in range(5):\n",
    "    ls.append(x)\n",
    "print(ls)\n",
    "\n",
    "sum=0\n",
    "# Store sum all the even numbers of the list ls in sum and print it\n",
    "\n",
    "for x in ls:\n",
    "    if x%2 == 0:\n",
    "        sum += x\n",
    "\n",
    "print (sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3 - Exploratory analysis in Python using Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case study - Who is eligible for loan?\n",
    "\n",
    "Introduction - Analytics Vidhya (AV) DataHack\n",
    "At [Analytics Vidhya](http://www.analyticsvidhya.com/), we are building a knowledge platform for data science professionals across the globe. Among several things, we host several hackathons for our community on our [DataHack platform](http://datahack.analyticsvidhya.com/). The case study for today's problem is one of the practice problem on our platform. You can check out the practice problem [here](http://datahack.analyticsvidhya.com/contest/practice-problem-loan-prediction-iii).\n",
    "\n",
    "The case study - Dream Housing Finance\n",
    "Dream Housing Finance company deals in all home loans. They have a presence across all urban, semi-urban and rural areas. Customers first apply for a home loan after that company validates the customer's eligibility. The company wants to automate the loan eligibility process (real-time) based on customer detail provided while filling online application form.\n",
    "\n",
    "Let's start with loading the training and testing set into your python environment. You will use the training set to build your model, and the test set to validate it. Both the files are stored on the web as CSV files; their URLs are already available as character strings in the sample code.\n",
    "\n",
    "You can load this data with the pandas.read_csv() function. It converts the data set to a python dataframe. In simple words, Python dataframe can be imagined as an equivalent of a spreadsheet or a SQL table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Loan_ID Gender Married Dependents     Education Self_Employed  \\\n",
      "0   LP001002   Male      No          0      Graduate            No   \n",
      "1   LP001003   Male     Yes          1      Graduate            No   \n",
      "2   LP001005   Male     Yes          0      Graduate           Yes   \n",
      "3   LP001006   Male     Yes          0  Not Graduate            No   \n",
      "4   LP001008   Male      No          0      Graduate            No   \n",
      "5   LP001011   Male     Yes          2      Graduate           Yes   \n",
      "6   LP001013   Male     Yes          0  Not Graduate            No   \n",
      "7   LP001014   Male     Yes         3+      Graduate            No   \n",
      "8   LP001018   Male     Yes          2      Graduate            No   \n",
      "9   LP001020   Male     Yes          1      Graduate            No   \n",
      "10  LP001024   Male     Yes          2      Graduate            No   \n",
      "11  LP001027   Male     Yes          2      Graduate           NaN   \n",
      "12  LP001028   Male     Yes          2      Graduate            No   \n",
      "13  LP001029   Male      No          0      Graduate            No   \n",
      "14  LP001030   Male     Yes          2      Graduate            No   \n",
      "15  LP001032   Male      No          0      Graduate            No   \n",
      "16  LP001034   Male      No          1  Not Graduate            No   \n",
      "\n",
      "    ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
      "0              5849                0.0         NaN             360.0   \n",
      "1              4583             1508.0       128.0             360.0   \n",
      "2              3000                0.0        66.0             360.0   \n",
      "3              2583             2358.0       120.0             360.0   \n",
      "4              6000                0.0       141.0             360.0   \n",
      "5              5417             4196.0       267.0             360.0   \n",
      "6              2333             1516.0        95.0             360.0   \n",
      "7              3036             2504.0       158.0             360.0   \n",
      "8              4006             1526.0       168.0             360.0   \n",
      "9             12841            10968.0       349.0             360.0   \n",
      "10             3200              700.0        70.0             360.0   \n",
      "11             2500             1840.0       109.0             360.0   \n",
      "12             3073             8106.0       200.0             360.0   \n",
      "13             1853             2840.0       114.0             360.0   \n",
      "14             1299             1086.0        17.0             120.0   \n",
      "15             4950                0.0       125.0             360.0   \n",
      "16             3596                0.0       100.0             240.0   \n",
      "\n",
      "    Credit_History Property_Area Loan_Status  \n",
      "0              1.0         Urban           Y  \n",
      "1              1.0         Rural           N  \n",
      "2              1.0         Urban           Y  \n",
      "3              1.0         Urban           Y  \n",
      "4              1.0         Urban           Y  \n",
      "5              1.0         Urban           Y  \n",
      "6              1.0         Urban           Y  \n",
      "7              0.0     Semiurban           N  \n",
      "8              1.0         Urban           Y  \n",
      "9              1.0     Semiurban           N  \n",
      "10             1.0         Urban           Y  \n",
      "11             1.0         Urban           Y  \n",
      "12             1.0         Urban           Y  \n",
      "13             1.0         Rural           N  \n",
      "14             1.0         Urban           Y  \n",
      "15             1.0         Urban           Y  \n",
      "16             NaN         Urban           Y  \n",
      "614\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "# import library pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Import training data as train\n",
    "train = pd.read_csv(\"https://s3-ap-southeast-1.amazonaws.com/av-datahack-datacamp/train.csv\")\n",
    "# replace balnk or na with zero using pandas to do this for the whole dataframe use df.fillna(0)\n",
    "# train['Credit_History'] = train['Credit_History'].fillna(0.0)\n",
    "\n",
    "\n",
    "# Import testing data as test\n",
    "test = pd.read_csv(\"https://s3-ap-southeast-1.amazonaws.com/av-datahack-datacamp/test.csv\")\n",
    "\n",
    "# Print top 5 observation of train dataset\n",
    "print (train.head(17) )\n",
    "\n",
    "# Store total number of observation in training dataset\n",
    "train_length = len (train)\n",
    "print(train_length)\n",
    "\n",
    "# Store total number of columns in testing data set\n",
    "test_col = len (test.columns)\n",
    "print(test_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Data\n",
    "\n",
    "You can look at a summary of numerical fields by using dataframe.describe(). It provides the count, mean, standard deviation (std), min, quartiles and max in its output.\n",
    "```\n",
    "dataframe.describe()\n",
    "```\n",
    "For the non-numeric values (e.g. PropertyArea, CreditHistory etc.), we can look at frequency distribution. The frequency table can be printed by the following command:\n",
    "\n",
    "```\n",
    "df[column_name].value_counts()\n",
    "OR\n",
    "df.column_name.value_counts()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
      "count       614.000000         614.000000  592.000000         600.00000   \n",
      "mean       5403.459283        1621.245798  146.412162         342.00000   \n",
      "std        6109.041673        2926.248369   85.587325          65.12041   \n",
      "min         150.000000           0.000000    9.000000          12.00000   \n",
      "25%        2877.500000           0.000000  100.000000         360.00000   \n",
      "50%        3812.500000        1188.500000  128.000000         360.00000   \n",
      "75%        5795.000000        2297.250000  168.000000         360.00000   \n",
      "max       81000.000000       41667.000000  700.000000         480.00000   \n",
      "\n",
      "       Credit_History  \n",
      "count      564.000000  \n",
      "mean         0.842199  \n",
      "std          0.364878  \n",
      "min          0.000000  \n",
      "25%          1.000000  \n",
      "50%          1.000000  \n",
      "75%          1.000000  \n",
      "max          1.000000  \n",
      "Semiurban    233\n",
      "Urban        202\n",
      "Rural        179\n",
      "Name: Property_Area, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Training and Testing data set are loaded in train and test dataframe respectively\n",
    "\n",
    "# Look at the summary of numerical variables for train data set\n",
    "df= train.describe()\n",
    "print (df)\n",
    "\n",
    "# Print the unique values and their frequency of variable Property_Area\n",
    "df1=train.Property_Area.value_counts()\n",
    "print (df1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding distribution of numerical variables\n",
    "\n",
    "Now that we are familiar with basic data characteristics, let us study the distribution of numerical variables. Let us start with numeric variable \"ApplicantIncome\".\n",
    "\n",
    "Let's start by plotting the histogram of ApplicantIncome using the following command:\n",
    "\n",
    "```\n",
    "train['ApplicantIncome'].hist(bins=50)\n",
    "```\n",
    "Or\n",
    "```\n",
    "train.ApplicantIncome.hist(bins=50)\n",
    "```\n",
    "Next, we can also look at box plots to understand the distributions. Box plot for ApplicantIncome can be plotted by\n",
    "```\n",
    "train.boxplot(column='ApplicantIncome')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'LoanAmount'}, xlabel='Gender'>"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training and Testing dataset are loaded in train and test dataframe respectively\n",
    "# Plot histogram for variable LoanAmount\n",
    "train.LoanAmount.hist(bins=50)\n",
    "\n",
    "\n",
    "# Plot a box plot for variable LoanAmount by variable Gender of training data set\n",
    "train.boxplot(column='LoanAmount', by = 'Gender')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding distribution of categorical variables\n",
    "\n",
    "We have looked at the distributions of ApplicantIncome and LoanIncome, now it's time for looking at categorical variables in more details. For instance, let's see whether Gender is affecting the loan status or not. This can be tested using cross-tabulation as shown below:\n",
    "```\n",
    "pd.crosstab( train ['Gender'], train [\"Loan_Status\"], margins=True)\n",
    "```\n",
    "Next, we can also look at proportions can be more intuitive in making some quick insights. We can do this using the apply function. You can read more about cross tab and apply functions [here](http://www.analyticsvidhya.com/blog/2016/01/12-pandas-techniques-python-data-manipulation/).\n",
    "\n",
    "```\n",
    "def percentageConvert(ser):\n",
    "  return ser/float(ser[-1])\n",
    "\n",
    "pd.crosstab(train [\"Gender\"], train [\"Loan_Status\"], margins=True).apply(percentageConvert, axis=1)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y    422\n",
      "N    192\n",
      "Name: Loan_Status, dtype: int64\n",
      "count     614\n",
      "unique      2\n",
      "top         Y\n",
      "freq      422\n",
      "Name: Loan_Status, dtype: object\n",
      "1.0    475\n",
      "0.0     89\n",
      "Name: Credit_History, dtype: int64\n",
      "count    564.000000\n",
      "mean       0.842199\n",
      "std        0.364878\n",
      "min        0.000000\n",
      "25%        1.000000\n",
      "50%        1.000000\n",
      "75%        1.000000\n",
      "max        1.000000\n",
      "Name: Credit_History, dtype: float64\n",
      "Loan_Status       N    Y  All\n",
      "Credit_History               \n",
      "0.0              82    7   89\n",
      "1.0              97  378  475\n",
      "All             179  385  564\n"
     ]
    }
   ],
   "source": [
    "# Training and Testing dataset are loaded in train and test dataframe respectively\n",
    "\n",
    "# Approved Loan in absolute numbers\n",
    "loan_approval = train['Loan_Status'].value_counts()['Y']\n",
    "print(train['Loan_Status'].value_counts())\n",
    "print(train['Loan_Status'].describe())\n",
    "\n",
    "print(train['Credit_History'].value_counts())\n",
    "print(train['Credit_History'].describe())\n",
    "\n",
    "# Two-way comparison: Credit History and Loan Status\n",
    "twowaytable = pd.crosstab(train [\"Credit_History\"], train [\"Loan_Status\"], margins=True)\n",
    "print(twowaytable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas Crosstab\n",
    "\n",
    "This function is used to get an initial “feel” (view) of the data. Here, we can validate some basic hypothesis. For instance, in this case, “Credit_History” is expected to affect the loan status significantly. This can be tested using cross-tabulation as shown below:\n",
    "\n",
    "```\n",
    "pd.crosstab(data[\"Credit_History\"],data[\"Loan_Status\"],margins=True)\n",
    "```\n",
    "These are absolute numbers. But, percentages can be more intuitive in making some quick insights. We can do this using the Pandas apply function:\n",
    "```\n",
    "def percConvert(ser):\n",
    "  return ser/float(ser[-1])\n",
    "  pd.crosstab(data[\"Credit_History\"],data[\"Loan_Status\"],margins=True).apply(percConvert, axis=1)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Loan_Status</th>\n",
       "      <th>N</th>\n",
       "      <th>Y</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Credit_History</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>82</td>\n",
       "      <td>7</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>97</td>\n",
       "      <td>378</td>\n",
       "      <td>475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>179</td>\n",
       "      <td>385</td>\n",
       "      <td>564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Loan_Status       N    Y  All\n",
       "Credit_History               \n",
       "0.0              82    7   89\n",
       "1.0              97  378  475\n",
       "All             179  385  564"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(train[\"Credit_History\"],train[\"Loan_Status\"],margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Loan_Status</th>\n",
       "      <th>N</th>\n",
       "      <th>Y</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Credit_History</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.921348</td>\n",
       "      <td>0.078652</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.204211</td>\n",
       "      <td>0.795789</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>0.317376</td>\n",
       "      <td>0.682624</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Loan_Status            N         Y  All\n",
       "Credit_History                         \n",
       "0.0             0.921348  0.078652  1.0\n",
       "1.0             0.204211  0.795789  1.0\n",
       "All             0.317376  0.682624  1.0"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def percConvert(ser):\n",
    "  return ser/float(ser[-1])\n",
    "\n",
    "pd.crosstab(train[\"Credit_History\"],train[\"Loan_Status\"],margins=True).apply(percConvert, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4 - Data Munging in Python using Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The curious case of missing values\n",
    "\n",
    "Rarely is the data captured perfectly in real world. People might not disclose few details or those details might not be available in the first place. This data set is no different. There are missing values in variables.\n",
    "\n",
    "We need to first find out which variables have missing values, and then see what is the best way to handle these missing values. The way to handle a missing value can depend on the number of missing values, the type of variable and the expected importance of those variables.\n",
    "\n",
    "So, let's start by finding out whether variable \"Credit_history\" has missing values or not and if so, how many observations are missing.\n",
    "```\n",
    "train['Credit_History'].isnull().sum()\n",
    "```\n",
    "isnull() helps to check the observation has missing value or not (It returns a boolean value TRUE or FALSE)\n",
    "sum() used to return the number of records have missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many missing values in variable \"Self_Employed\" ?\n",
    "n_missing_value_Self_Employed = train['Self_Employed'].isnull().sum()\n",
    "print(n_missing_value_Self_Employed)\n",
    "print(train['Credit_History'].isnull().sum())\n",
    "\n",
    "# Variable Loan amount has missing values or not?\n",
    "train['LoanAmount'].isnull().sum() > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many variables have missing values?\n",
    "\n",
    "Till now, we have checked the variable has missing value or not? Next action is to check how many variables have missing values. One way of doing this check would be to evaluate each individual variable. This would not be easy if we have hundred of columns. This action can be performed simply by using isnull() on dataframe object.\n",
    "```\n",
    "train.isnull().sum()\n",
    "```\n",
    "This statement will return the column names with the number of observation that have missing (null) values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loan_ID               0\n",
      "Gender               11\n",
      "Married               0\n",
      "Dependents           10\n",
      "Education             0\n",
      "Self_Employed        23\n",
      "ApplicantIncome       0\n",
      "CoapplicantIncome     0\n",
      "LoanAmount            5\n",
      "Loan_Amount_Term      6\n",
      "Credit_History       29\n",
      "Property_Area         0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Loan_ID               0\n",
       "Gender               13\n",
       "Married               3\n",
       "Dependents           15\n",
       "Education             0\n",
       "Self_Employed        32\n",
       "ApplicantIncome       0\n",
       "CoapplicantIncome     0\n",
       "LoanAmount           22\n",
       "Loan_Amount_Term     14\n",
       "Credit_History       50\n",
       "Property_Area         0\n",
       "Loan_Status           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check variables have missing values in test data set\n",
    "print(test.isnull().sum())\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputing missing values of LoanAmount\n",
    "\n",
    "There are multiple ways to fill the missing values of continuous variables. You can replace them with mean, median or estimate values based on other features of the data set.\n",
    "\n",
    "For the sake of simplicity, we would impute the missing values of LoanAmount by mean value (Mean of available values of LoanAmount).\n",
    "```\n",
    "train['LoanAmount'].fillna(train['LoanAmount'].mean(), inplace=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing value of LoanAmount with 168 for test data set\n",
    "test['LoanAmount'].fillna(168, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impute missing values of SelfEmployed\n",
    "\n",
    "Similarly, to impute missing values of Categorical variables, we look at the frequency table. The simplest way is to impute with value which has highest frequency because there is a higher probability of success.\n",
    "\n",
    "For example, if you look at the distribution of SelfEmployed 500 out of 582 which is ~86% of total values falls under the category \"No\". Here we will replace missing values of SelfEmployed with \"No\".\n",
    "```\n",
    "train['Self_Employed'].fillna('No',inplace=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male      489\n",
      "Female    112\n",
      "Name: Gender, dtype: int64\n",
      "1.0    475\n",
      "0.0     89\n",
      "Name: Credit_History, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Impute missing value of Gender (Male is more frequent category)\n",
    "print(train['Gender'].value_counts())\n",
    "train['Gender'].fillna(\"Male\",inplace=True)\n",
    "\n",
    "\n",
    "# Impute missing value of Credit_History ( 1 is more frequent category)\n",
    "print(train['Credit_History'].value_counts())\n",
    "train['Credit_History'].fillna(1.0,inplace=True)\n",
    "\n",
    "train['LoanAmount'].fillna(train['LoanAmount'].mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treat / Tranform extreme values of LoanAmount and ApplicantIncome\n",
    "\n",
    "Let’s analyze LoanAmount first. Since the extreme values are practically possible, i.e. some people might apply for high-value loans due to specific needs.\n",
    "```\n",
    "train ['LoanAmount'].hist(bins=20)\n",
    "```\n",
    "So instead of treating them as outliers, let’s try a log transformation to nullify their effect:\n",
    "```\n",
    "import numpy as np\n",
    "train ['LoanAmount_log'] = np.log(train['LoanAmount'])\n",
    "train ['LoanAmount_log'].hist(bins=20)\n",
    "```\n",
    "Now the distribution looks much closer to normal and effect of extreme values has been significantly subsided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train ['LoanAmount'].hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>600.00000</td>\n",
       "      <td>614.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5403.459283</td>\n",
       "      <td>1621.245798</td>\n",
       "      <td>146.412162</td>\n",
       "      <td>342.00000</td>\n",
       "      <td>0.855049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6109.041673</td>\n",
       "      <td>2926.248369</td>\n",
       "      <td>84.037468</td>\n",
       "      <td>65.12041</td>\n",
       "      <td>0.352339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>12.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2877.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.250000</td>\n",
       "      <td>360.00000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3812.500000</td>\n",
       "      <td>1188.500000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>360.00000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5795.000000</td>\n",
       "      <td>2297.250000</td>\n",
       "      <td>164.750000</td>\n",
       "      <td>360.00000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>81000.000000</td>\n",
       "      <td>41667.000000</td>\n",
       "      <td>700.000000</td>\n",
       "      <td>480.00000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
       "count       614.000000         614.000000  614.000000         600.00000   \n",
       "mean       5403.459283        1621.245798  146.412162         342.00000   \n",
       "std        6109.041673        2926.248369   84.037468          65.12041   \n",
       "min         150.000000           0.000000    9.000000          12.00000   \n",
       "25%        2877.500000           0.000000  100.250000         360.00000   \n",
       "50%        3812.500000        1188.500000  129.000000         360.00000   \n",
       "75%        5795.000000        2297.250000  164.750000         360.00000   \n",
       "max       81000.000000       41667.000000  700.000000         480.00000   \n",
       "\n",
       "       Credit_History  \n",
       "count      614.000000  \n",
       "mean         0.855049  \n",
       "std          0.352339  \n",
       "min          0.000000  \n",
       "25%          1.000000  \n",
       "50%          1.000000  \n",
       "75%          1.000000  \n",
       "max          1.000000  "
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAARpklEQVR4nO3dX4xc51nH8e+PuLRuTJtEaRfLjtgAVqGt+dOuwp+IakwoDaSqc0ElV2nlQJGFFEpARuDARcRFRCQUoBcUyUpKLRFqQtoqFoFSyzBUXKTFTgtO4pZErUmdpHGhTWFDlLLl4WJP0GKPu7szszuzr78fyZo57zlzzqNHM789++6Z41QVkqS2fNukC5AkjZ/hLkkNMtwlqUGGuyQ1yHCXpAZtmnQBAFdeeWXNzs7y/PPPc+mll066nKljXwazL+ezJ4O12pcTJ078W1W9ZtC6qQj32dlZjh8/Tr/fp9frTbqcqWNfBrMv57Mng7XalyT/eqF1TstIUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDpuIbqpLON3vgwVW/Zv/OBW4+8CCn77xhDSrSRuKZuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1KBlwz3JB5OcTfLIgHW/nqSSXLlk7LYkTyT5fJK3jbtgSdLyVnLm/iHg+nMHk1wFvBV4csnY64E9wBu613wgySVjqVSStGLLhntVfRL46oBVfwD8BlBLxnYDh6vqxar6IvAEcM04CpUkrdxQt/xN8g7gqar6pyRLV20DHlqyfKYbG7SPfcA+gJmZGfr9PvPz8/T7/WFKapp9Gaz1vuzfubDq18xsXnxdy30ZRuvvlUFWHe5JXgn8NvDTg1YPGKsBY1TVQeAgwNzcXPV6Pfr9Pr1eb7UlNc++DNZ6X24e8n7ud53cxOmbeuMvaANr/b0yyDBn7t8DXA28dNa+HXg4yTUsnqlftWTb7cDToxYpSVqdVV8KWVUnq+q1VTVbVbMsBvqbqurLwBFgT5KXJ7ka2AF8eqwVS5KWteyZe5IPAz3gyiRngNur6p5B21bVo0nuAx4DFoBbquqbY6xX2lCG+a/ypHFYNtyr6l3LrJ89Z/kO4I7RypIkjcJvqEpSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJatCy4Z7kg0nOJnlkydjvJflckn9O8rEkly1Zd1uSJ5J8Psnb1qhuSdK3sJIz9w8B158zdhR4Y1X9APAvwG0ASV4P7AHe0L3mA0kuGVu1kqQVWTbcq+qTwFfPGftEVS10iw8B27vnu4HDVfViVX0ReAK4Zoz1SpJWYNMY9vELwJ93z7exGPYvOdONnSfJPmAfwMzMDP1+n/n5efr9/hhKaot9GWwj9GX/zoXlNxqjmc2Lx5z2vqy3jfBeGbeRwj3JbwMLwL0vDQ3YrAa9tqoOAgcB5ubmqtfr0e/36fV6o5TUJPsy2Eboy80HHlzX4+3fucBdJzdx+qbeuh532m2E98q4DR3uSfYCbweuq6qXAvwMcNWSzbYDTw9fniRpGENdCpnkeuA3gXdU1X8tWXUE2JPk5UmuBnYAnx69TEnSaix75p7kw0APuDLJGeB2Fq+OeTlwNAnAQ1X1S1X1aJL7gMdYnK65paq+uVbFS5IGWzbcq+pdA4bv+Rbb3wHcMUpRkqTR+A1VSWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNWjbck3wwydkkjywZuyLJ0SSPd4+XL1l3W5Inknw+ydvWqnBJ0oWt5Mz9Q8D154wdAI5V1Q7gWLdMktcDe4A3dK/5QJJLxlatJGlFlg33qvok8NVzhncDh7rnh4Abl4wfrqoXq+qLwBPANeMpVZK0UsPOuc9U1TMA3eNru/FtwJeWbHemG5MkraNNY95fBozVwA2TfcA+gJmZGfr9PvPz8/T7/TGXtPHZl8E2Ql/271xY1+PNbF485rT3Zb1thPfKuA0b7s8m2VpVzyTZCpztxs8AVy3Zbjvw9KAdVNVB4CDA3Nxc9Xo9+v0+vV5vyJLaZV8G2wh9ufnAg+t6vP07F7jr5CY4+fxI+zl95w1jqmg6bIT3yrgNOy1zBNjbPd8LPLBkfE+Slye5GtgBfHq0EiVJq7XsmXuSDwM94MokZ4DbgTuB+5K8F3gSeCdAVT2a5D7gMWABuKWqvrlGtUuSLmDZcK+qd11g1XUX2P4O4I5RipIkjcZvqEpSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNGinck/xakkeTPJLkw0lekeSKJEeTPN49Xj6uYiVJKzN0uCfZBvwKMFdVbwQuAfYAB4BjVbUDONYtS5LW0ajTMpuAzUk2Aa8EngZ2A4e69YeAG0c8hiRplVJVw784uRW4A3gB+ERV3ZTkuaq6bMk2X6uq86ZmkuwD9gHMzMy8+fDhw8zPz7Nly5ah62mVfRlsI/Tl5FNfX9fjzWyGZ18YfT87t7169J1MkY3wXhnGrl27TlTV3KB1m4bdaTeXvhu4GngO+Isk717p66vqIHAQYG5urnq9Hv1+n16vN2xJzbIvg22Evtx84MF1Pd7+nQvcdXLoj/X/OX1Tb/RipshGeK+M2yjTMj8FfLGqvlJV/w18FPhx4NkkWwG6x7OjlylJWo1Rwv1J4EeTvDJJgOuAU8ARYG+3zV7ggdFKlCSt1tC/v1XVp5LcDzwMLACfYXGaZQtwX5L3svgD4J3jKFSStHIjTc5V1e3A7ecMv8jiWbwkaUL8hqokNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1aPT/Jl1q3OyBByddgrRqI525J7ksyf1JPpfkVJIfS3JFkqNJHu8eLx9XsZKklRl1Wub9wMer6vuAHwROAQeAY1W1AzjWLUuS1tHQ4Z7kVcBbgHsAquobVfUcsBs41G12CLhxtBIlSas1ypn7dwNfAf4kyWeS3J3kUmCmqp4B6B5fO4Y6JUmrkKoa7oXJHPAQcG1VfSrJ+4H/AN5XVZct2e5rVXXevHuSfcA+gJmZmTcfPnyY+fl5tmzZMlQ9LbMvg61XX04+9fU1P8a4zGyGZ18YfT87t7169J1MkVY/Q7t27TpRVXOD1o0S7t8JPFRVs93yT7A4v/69QK+qnkmyFehX1eu+1b7m5ubq+PHj9Pt9er3eUPW0zL4Mtl592UhXy+zfucBdJ0e/CO70nTeMoZrp0epnKMkFw33oaZmq+jLwpSQvBfd1wGPAEWBvN7YXeGDYY0iShjPqj/j3Afcm+XbgC8DPs/gD474k7wWeBN454jEkSas0UrhX1WeBQb8SXDfKfiVJo/H2A5LUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDRg73JJck+UySv+yWr0hyNMnj3ePlo5cpSVqNcZy53wqcWrJ8ADhWVTuAY92yJGkdjRTuSbYDNwB3LxneDRzqnh8CbhzlGJKk1UtVDf/i5H7gd4HvAH69qt6e5LmqumzJNl+rqvOmZpLsA/YBzMzMvPnw4cPMz8+zZcuWoetplX0ZbL36cvKpr6/5McZlZjM8+8Lo+9m57dWj72SKtPoZ2rVr14mqmhu0btOwO03yduBsVZ1I0lvt66vqIHAQYG5urnq9Hv1+n15v1btqnn0ZbL36cvOBB9f8GOOyf+cCd50c+mP9f07f1Bu9mClyMX6GRnkXXAu8I8nPAq8AXpXkT4Fnk2ytqmeSbAXOjqNQSdLKDT3nXlW3VdX2qpoF9gB/W1XvBo4Ae7vN9gIPjFylJGlV1uI69zuBtyZ5HHhrtyxJWkejT84BVdUH+t3zfweuG8d+JUnD8RuqktQgw12SGmS4S1KDDHdJapDhLkkNGsvVMtK0m91A3zKdBqP06/SdN4yxEg3LM3dJapDhLkkNMtwlqUHOuUsaK+frp4Nn7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGDR3uSa5K8ndJTiV5NMmt3fgVSY4mebx7vHx85UqSVmKUM/cFYH9VfT/wo8AtSV4PHACOVdUO4Fi3LElaR0OHe1U9U1UPd8//EzgFbAN2A4e6zQ4BN45YoyRplVJVo+8kmQU+CbwReLKqLluy7mtVdd7UTJJ9wD6AmZmZNx8+fJj5+Xm2bNkycj2tsS+DraYvJ5/6+hpXMx1mNsOzL0y6iuHt3PbqNdlvq5+hXbt2naiquUHrRg73JFuAvwfuqKqPJnluJeG+1NzcXB0/fpx+v0+v1xupnhbZl8FW05eL5T/r2L9zgbtObtz7Aa7VjcNa/QwluWC4j3S1TJKXAR8B7q2qj3bDzybZ2q3fCpwd5RiSpNUb5WqZAPcAp6rq95esOgLs7Z7vBR4YvjxJ0jBG+f3tWuA9wMkkn+3Gfgu4E7gvyXuBJ4F3jlShxOBplf07F7j5IplukVZr6HCvqn8AcoHV1w27X0nS6PyGqiQ1yHCXpAYZ7pLUIMNdkhq0cb/tIKk5o3zZbK2+ALVRGe5aNxfLt0SlaeC0jCQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQl0JKuuiNepnuNF5j75m7JDXIM3dJTfhWZ98X473/DXdJGtE03jbBcNeqeAsBaWNwzl2SGuSZ+wbU4l/2JY3XmoV7kuuB9wOXAHdX1Z1rdSytjlMrUvvWJNyTXAL8EfBW4Azwj0mOVNVja3G8Sf0xYxr/iCJJsHZz7tcAT1TVF6rqG8BhYPcaHUuSdI5U1fh3mvwccH1V/WK3/B7gR6rql5dssw/Y1y2+Dvg8cCXwb2MvaOOzL4PZl/PZk8Fa7ct3VdVrBq1Yqzn3DBj7fz9FquogcPD/vSg5XlVza1TThmVfBrMv57Mng12MfVmraZkzwFVLlrcDT6/RsSRJ51ircP9HYEeSq5N8O7AHOLJGx5IknWNNpmWqaiHJLwN/w+KlkB+sqkdX8NKDy29yUbIvg9mX89mTwS66vqzJH1QlSZPl7QckqUGGuyQ1aOLhnuSqJH+X5FSSR5PcOumapkGSVyT5dJJ/6vryO5OuaZokuSTJZ5L85aRrmRZJTic5meSzSY5Pup5pkeSyJPcn+VyXMz826ZrWwzTcOGwB2F9VDyf5DuBEkqNrdauCDeRF4Ceraj7Jy4B/SPLXVfXQpAubErcCp4BXTbqQKbOrqlr8ss4o3g98vKp+rrt675WTLmg9TPzMvaqeqaqHu+f/yeIHdttkq5q8WjTfLb6s++dfv4Ek24EbgLsnXYumW5JXAW8B7gGoqm9U1XMTLWqdTDzcl0oyC/ww8KkJlzIVuqmHzwJngaNVZV8W/SHwG8D/TLiOaVPAJ5Kc6G7vIfhu4CvAn3TTeHcnuXTSRa2HqQn3JFuAjwC/WlX/Mel6pkFVfbOqfojFb/hek+SNEy5p4pK8HThbVScmXcsUuraq3gT8DHBLkrdMuqApsAl4E/DHVfXDwPPAgcmWtD6mIty7OeWPAPdW1UcnXc+06X6N7APXT7aSqXAt8I4kp1m82+hPJvnTyZY0Harq6e7xLPAxFu/OerE7A5xZ8lvv/SyGffMmHu5JwuJ82Kmq+v1J1zMtkrwmyWXd883ATwGfm2hRU6Cqbquq7VU1y+JtLf62qt494bImLsml3QUJdNMOPw08MtmqJq+qvgx8KcnruqHrgIviYo1puFrmWuA9wMlufhngt6rqryZX0lTYChzq/uOTbwPuqyov+9OFzAAfWzxXYhPwZ1X18cmWNDXeB9zbXSnzBeDnJ1zPuvD2A5LUoIlPy0iSxs9wl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ36XzM7GSPB0M1BAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "train ['LoanAmount_log'] = np.log(train['LoanAmount'])\n",
    "train ['LoanAmount_log'].hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>LoanAmount_log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>600.00000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5403.459283</td>\n",
       "      <td>1621.245798</td>\n",
       "      <td>146.412162</td>\n",
       "      <td>342.00000</td>\n",
       "      <td>0.855049</td>\n",
       "      <td>4.862066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6109.041673</td>\n",
       "      <td>2926.248369</td>\n",
       "      <td>84.037468</td>\n",
       "      <td>65.12041</td>\n",
       "      <td>0.352339</td>\n",
       "      <td>0.496575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>12.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.197225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2877.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.250000</td>\n",
       "      <td>360.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.607658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3812.500000</td>\n",
       "      <td>1188.500000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>360.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.859812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5795.000000</td>\n",
       "      <td>2297.250000</td>\n",
       "      <td>164.750000</td>\n",
       "      <td>360.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.104426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>81000.000000</td>\n",
       "      <td>41667.000000</td>\n",
       "      <td>700.000000</td>\n",
       "      <td>480.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.551080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
       "count       614.000000         614.000000  614.000000         600.00000   \n",
       "mean       5403.459283        1621.245798  146.412162         342.00000   \n",
       "std        6109.041673        2926.248369   84.037468          65.12041   \n",
       "min         150.000000           0.000000    9.000000          12.00000   \n",
       "25%        2877.500000           0.000000  100.250000         360.00000   \n",
       "50%        3812.500000        1188.500000  129.000000         360.00000   \n",
       "75%        5795.000000        2297.250000  164.750000         360.00000   \n",
       "max       81000.000000       41667.000000  700.000000         480.00000   \n",
       "\n",
       "       Credit_History  LoanAmount_log  \n",
       "count      614.000000      614.000000  \n",
       "mean         0.855049        4.862066  \n",
       "std          0.352339        0.496575  \n",
       "min          0.000000        2.197225  \n",
       "25%          1.000000        4.607658  \n",
       "50%          1.000000        4.859812  \n",
       "75%          1.000000        5.104426  \n",
       "max          1.000000        6.551080  "
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training and Testing datasets are loaded in variable train and test dataframe respectively\n",
    "\n",
    "# Add both ApplicantIncome and CoapplicantIncome to TotalIncome\n",
    "train['TotalIncome'] = train['ApplicantIncome'] + train['CoapplicantIncome']\n",
    "\n",
    "# Perform log transformation of TotalIncome to make it closer to normal\n",
    "train['TotalIncome_log']= np.log(train['TotalIncome'])\n",
    "train['TotalIncome_log'].hist(bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 5 - Building a Predictive model in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Step of Model Building\n",
    "\n",
    "In Python, Scikit-Learn (sklearn) is the most commonly used library for building predictive / machine learning models. [This article provides a good overview of scikit-learn](http://www.analyticsvidhya.com/blog/2015/01/scikit-learn-python-machine-learning-tool/). It has gathered a lot of interest recently for model building. There are few pre-requisite before jumping into a model building exercise:\n",
    "\n",
    "Treat missing values\n",
    "Treat outlier/ exponential observation\n",
    "All inputs must be numeric array ( Requirement of scikit learn library)\n",
    "Can we build a model without treating missing values of a data set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label categories of Gender to number\n",
    "\n",
    "Library \"Scikit Learn\" only works with numeric array. Hence, we need to label all the character variables into a numeric array. For example Variable \"Gender\" has two labels \"Male\" and \"Female\". Hence, we will transform the labels to number as 1 for \"Male\" and 0 for \"Female\".\n",
    "\n",
    "\"Scikit Learn\" library has a module called \"LabelEncoder\" which helps to label character labels into numbers so first import module \"LabelEncoder\".\n",
    "\n",
    "```\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "number = LabelEncoder()\n",
    "\n",
    "train['Gender'] = number.fit_transform(train['Gender'].astype(str))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import module for label encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#train and test dataset is already loaded in the enviornment\n",
    "# Perform label encoding for variable 'Married'\n",
    "number = LabelEncoder()\n",
    "train['Married_new'] = number.fit_transform(train['Married'].astype(str))\n",
    "train['Education_new'] = number.fit_transform(train['Education'].astype(str))\n",
    "train['Property_Area_new'] = number.fit_transform(train['Property_Area'].astype(str))\n",
    "train['Gender_new'] = number.fit_transform(train['Gender'].astype(str))\n",
    "train['Loan_Status_new'] = number.fit_transform(train['Loan_Status'].astype(str))\n",
    "train['Loan_Status_new_tree'] = number.fit_transform(train['Loan_Status'].astype(str))\n",
    "train['Loan_Status_new_forest'] = number.fit_transform(train['Loan_Status'].astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting the right algorithm\n",
    "\n",
    "The basic principle behind selecting the right algorithm is to look at the dependent variable (or target variable). In this challenge \"Loan Prediction\", we need to classify a customer's eligibility for Loan as \"Y\" or \"N\" based on the available information about the customer. Here the dependent variable is categorical and our task is to classify the customer in two groups; eligible for the loan amount and not eligible for the loan amount.\n",
    "\n",
    "This is a classification challenge so we will import module of classification algorithms of sklearn library. Below are some commonly used classification algorithms: \n",
    "* Logistic Regression \n",
    "* Decision Tree \n",
    "* Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Have you performed data preprocessing step?\n",
    "\n",
    "As discussed before, you should perform some data pre processing steps for both train and test dataset before jumping into model building exercise. Here are a few things you need to perform at the minimum: \n",
    "* Missing value imputation \n",
    "* Outlier treatment \n",
    "* Label encoding for character variables \n",
    "* Algorithm selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Introduction\n",
    "\n",
    "Logistic Regression is a classification algorithm. It is used to predict a binary outcome (1 / 0, Yes / No, True / False) given a set of independent variables. To represent binary / categorical outcome, we use dummy variables. You can also think of logistic regression as a special case of linear regression when the outcome variable is categorical, where we are using log of odds as the dependent variable.\n",
    "\n",
    "In simple words, it predicts the probability of occurrence of an event by fitting data to a logit function, read more about [Logistic Regression](http://www.analyticsvidhya.com/blog/2015/11/beginners-guide-on-logistic-regression-in-r/).\n",
    "\n",
    "LogisticRegression() function is part of linear_model module of sklearn and is used to create logistic regression\n",
    "\n",
    "Reference: [Mathematical working and implementation from scratch for Logistic regression](http://www.analyticsvidhya.com/blog/2015/10/basics-logistic-regression/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import linear model of sklearn\n",
    "import sklearn.linear_model\n",
    "\n",
    "# Create object of Logistic Regression\n",
    "model=sklearn.linear_model.LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build your first logistic regression model\n",
    "\n",
    "Let’s build our first Logistic Regression model. One way would be to take all the variables into the model, but this might result in overfitting (don’t worry if you’re unaware of this terminology yet). In simple words, taking all variables might result in the model understanding complex relations specific to the data and will not generalize well.\n",
    "\n",
    "We can easily make some intuitive hypothesis to set the ball rolling. The chances of getting a loan will be higher for:\n",
    "\n",
    "Applicants having a credit history\n",
    "Applicants with higher applicant and co-applicant income\n",
    "Applicants with higher education level\n",
    "Properties in urban areas with high growth perspectives\n",
    "Ok, time for you to build your first logistics regression model! The pre processed trainmodified and testmodifed data are available in your workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>...</th>\n",
       "      <th>LoanAmount_log</th>\n",
       "      <th>TotalIncome</th>\n",
       "      <th>TotalIncome_log</th>\n",
       "      <th>Married_new</th>\n",
       "      <th>Education_new</th>\n",
       "      <th>Property_Area_new</th>\n",
       "      <th>Gender_new</th>\n",
       "      <th>Loan_Status_new</th>\n",
       "      <th>Loan_Status_new_tree</th>\n",
       "      <th>Loan_Status_new_forest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LP001002</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>5849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>146.412162</td>\n",
       "      <td>360.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.986426</td>\n",
       "      <td>5849.0</td>\n",
       "      <td>8.674026</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LP001003</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>4583</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>360.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.852030</td>\n",
       "      <td>6091.0</td>\n",
       "      <td>8.714568</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LP001005</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>360.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.189655</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>8.006368</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LP001006</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2583</td>\n",
       "      <td>2358.0</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>360.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.787492</td>\n",
       "      <td>4941.0</td>\n",
       "      <td>8.505323</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LP001008</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>6000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>360.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.948760</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>8.699515</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LP001011</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>5417</td>\n",
       "      <td>4196.0</td>\n",
       "      <td>267.000000</td>\n",
       "      <td>360.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.587249</td>\n",
       "      <td>9613.0</td>\n",
       "      <td>9.170872</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LP001013</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2333</td>\n",
       "      <td>1516.0</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>360.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.553877</td>\n",
       "      <td>3849.0</td>\n",
       "      <td>8.255569</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LP001014</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3+</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>3036</td>\n",
       "      <td>2504.0</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>360.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.062595</td>\n",
       "      <td>5540.0</td>\n",
       "      <td>8.619750</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LP001018</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>4006</td>\n",
       "      <td>1526.0</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>360.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.123964</td>\n",
       "      <td>5532.0</td>\n",
       "      <td>8.618305</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LP001020</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>12841</td>\n",
       "      <td>10968.0</td>\n",
       "      <td>349.000000</td>\n",
       "      <td>360.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.855072</td>\n",
       "      <td>23809.0</td>\n",
       "      <td>10.077819</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LP001024</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>3200</td>\n",
       "      <td>700.0</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>360.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.248495</td>\n",
       "      <td>3900.0</td>\n",
       "      <td>8.268732</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LP001027</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2500</td>\n",
       "      <td>1840.0</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>360.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.691348</td>\n",
       "      <td>4340.0</td>\n",
       "      <td>8.375630</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LP001028</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>3073</td>\n",
       "      <td>8106.0</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>360.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.298317</td>\n",
       "      <td>11179.0</td>\n",
       "      <td>9.321792</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LP001029</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>1853</td>\n",
       "      <td>2840.0</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>360.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.736198</td>\n",
       "      <td>4693.0</td>\n",
       "      <td>8.453827</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LP001030</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>1299</td>\n",
       "      <td>1086.0</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>120.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.833213</td>\n",
       "      <td>2385.0</td>\n",
       "      <td>7.776954</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LP001032</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>4950</td>\n",
       "      <td>0.0</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>360.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.828314</td>\n",
       "      <td>4950.0</td>\n",
       "      <td>8.507143</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LP001034</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>3596</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>240.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.605170</td>\n",
       "      <td>3596.0</td>\n",
       "      <td>8.187577</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Loan_ID Gender Married Dependents     Education Self_Employed  \\\n",
       "0   LP001002   Male      No          0      Graduate            No   \n",
       "1   LP001003   Male     Yes          1      Graduate            No   \n",
       "2   LP001005   Male     Yes          0      Graduate           Yes   \n",
       "3   LP001006   Male     Yes          0  Not Graduate            No   \n",
       "4   LP001008   Male      No          0      Graduate            No   \n",
       "5   LP001011   Male     Yes          2      Graduate           Yes   \n",
       "6   LP001013   Male     Yes          0  Not Graduate            No   \n",
       "7   LP001014   Male     Yes         3+      Graduate            No   \n",
       "8   LP001018   Male     Yes          2      Graduate            No   \n",
       "9   LP001020   Male     Yes          1      Graduate            No   \n",
       "10  LP001024   Male     Yes          2      Graduate            No   \n",
       "11  LP001027   Male     Yes          2      Graduate           NaN   \n",
       "12  LP001028   Male     Yes          2      Graduate            No   \n",
       "13  LP001029   Male      No          0      Graduate            No   \n",
       "14  LP001030   Male     Yes          2      Graduate            No   \n",
       "15  LP001032   Male      No          0      Graduate            No   \n",
       "16  LP001034   Male      No          1  Not Graduate            No   \n",
       "\n",
       "    ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  ...  \\\n",
       "0              5849                0.0  146.412162             360.0  ...   \n",
       "1              4583             1508.0  128.000000             360.0  ...   \n",
       "2              3000                0.0   66.000000             360.0  ...   \n",
       "3              2583             2358.0  120.000000             360.0  ...   \n",
       "4              6000                0.0  141.000000             360.0  ...   \n",
       "5              5417             4196.0  267.000000             360.0  ...   \n",
       "6              2333             1516.0   95.000000             360.0  ...   \n",
       "7              3036             2504.0  158.000000             360.0  ...   \n",
       "8              4006             1526.0  168.000000             360.0  ...   \n",
       "9             12841            10968.0  349.000000             360.0  ...   \n",
       "10             3200              700.0   70.000000             360.0  ...   \n",
       "11             2500             1840.0  109.000000             360.0  ...   \n",
       "12             3073             8106.0  200.000000             360.0  ...   \n",
       "13             1853             2840.0  114.000000             360.0  ...   \n",
       "14             1299             1086.0   17.000000             120.0  ...   \n",
       "15             4950                0.0  125.000000             360.0  ...   \n",
       "16             3596                0.0  100.000000             240.0  ...   \n",
       "\n",
       "    LoanAmount_log TotalIncome TotalIncome_log  Married_new  Education_new  \\\n",
       "0         4.986426      5849.0        8.674026            0              0   \n",
       "1         4.852030      6091.0        8.714568            1              0   \n",
       "2         4.189655      3000.0        8.006368            1              0   \n",
       "3         4.787492      4941.0        8.505323            1              1   \n",
       "4         4.948760      6000.0        8.699515            0              0   \n",
       "5         5.587249      9613.0        9.170872            1              0   \n",
       "6         4.553877      3849.0        8.255569            1              1   \n",
       "7         5.062595      5540.0        8.619750            1              0   \n",
       "8         5.123964      5532.0        8.618305            1              0   \n",
       "9         5.855072     23809.0       10.077819            1              0   \n",
       "10        4.248495      3900.0        8.268732            1              0   \n",
       "11        4.691348      4340.0        8.375630            1              0   \n",
       "12        5.298317     11179.0        9.321792            1              0   \n",
       "13        4.736198      4693.0        8.453827            0              0   \n",
       "14        2.833213      2385.0        7.776954            1              0   \n",
       "15        4.828314      4950.0        8.507143            0              0   \n",
       "16        4.605170      3596.0        8.187577            0              1   \n",
       "\n",
       "    Property_Area_new  Gender_new  Loan_Status_new  Loan_Status_new_tree  \\\n",
       "0                   2           1                1                     1   \n",
       "1                   0           1                0                     0   \n",
       "2                   2           1                1                     1   \n",
       "3                   2           1                1                     1   \n",
       "4                   2           1                1                     1   \n",
       "5                   2           1                1                     1   \n",
       "6                   2           1                1                     1   \n",
       "7                   1           1                0                     0   \n",
       "8                   2           1                1                     1   \n",
       "9                   1           1                0                     0   \n",
       "10                  2           1                1                     1   \n",
       "11                  2           1                1                     1   \n",
       "12                  2           1                1                     1   \n",
       "13                  0           1                0                     0   \n",
       "14                  2           1                1                     1   \n",
       "15                  2           1                1                     1   \n",
       "16                  2           1                1                     1   \n",
       "\n",
       "    Loan_Status_new_forest  \n",
       "0                        1  \n",
       "1                        0  \n",
       "2                        1  \n",
       "3                        1  \n",
       "4                        1  \n",
       "5                        1  \n",
       "6                        1  \n",
       "7                        0  \n",
       "8                        1  \n",
       "9                        0  \n",
       "10                       1  \n",
       "11                       1  \n",
       "12                       1  \n",
       "13                       0  \n",
       "14                       1  \n",
       "15                       1  \n",
       "16                       1  \n",
       "\n",
       "[17 rows x 23 columns]"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_modified and test_modified already loaded in the workspace\n",
    "#Import module for Logistic regression\n",
    "import sklearn.linear_model\n",
    "\n",
    "# Select three predictors Credit_History, Education and Gender\n",
    "predictors =['Property_Area_new','Credit_History','Married_new','Education_new','Gender_new','TotalIncome_log','LoanAmount_log']\n",
    "\n",
    "# Converting predictors and outcome to numpy array\n",
    "x_train = train[predictors].values\n",
    "y_train = train['Loan_Status_new'].values\n",
    "\n",
    "# Model Building\n",
    "model = sklearn.linear_model.LogisticRegression()\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction and submission to DataHack\n",
    "\n",
    "To upload a submission to DataHack, you need to predict the loan approval rate for the observations in the test set. This can be done using \".predict()\" method with logistic regression object (model). To extract the test features we will need to create a numpy array of input features of test data set in the same way as we did when training the model for training data.\n",
    "\n",
    "Next, you need to make sure your output is in line with the submission requirements of DataHack: a csv file with exactly 367 entries and two columns: LoanID and LoanStatus. Then create a csv file using to_csv() method from Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_modified already loaded in the workspace\n",
    "\n",
    "# Select three predictors Credit_History, Education and Gender \n",
    "predictors =['Property_Area_new','Credit_History','Married_new','Education_new','Gender_new','TotalIncome_log','LoanAmount_log']\n",
    "\n",
    "# Converting predictors and outcome to numpy array\n",
    "x_train = train[predictors].values\n",
    "\n",
    "#Predict Output\n",
    "predicted = model.predict(x_train)\n",
    "\n",
    "#Reverse encoding for predicted outcome\n",
    "predicted = number.inverse_transform(predicted)\n",
    "\n",
    "#Store it to test dataset\n",
    "train['Loan_Status_new'] = predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Output file to make submission\n",
    "#train.to_csv('myfistexport.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Y    525\n",
       "N     89\n",
       "Name: Loan_Status_new, dtype: int64"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Loan_Status_new'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Introduction\n",
    "\n",
    "Decision trees are mostly used in classification problems. It works for both categorical and continuous input and output variables. In this technique, we split the population or sample into two or more homogeneous sets (or sub-populations) based on most significant splitter / differentiator in input variables, read more about [Decision Tree](http://www.analyticsvidhya.com/blog/2015/01/decision-tree-simplified/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import tree module of sklearn\n",
    "import sklearn.tree\n",
    "\n",
    "# Create object of DecisionTreeClassifier\n",
    "model = sklearn.tree.DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model and do prediction using Decision Tree\n",
    "\n",
    "Let’s make first Decision Tree model. Similar to Logistic regression, we first select the input features, train our model and finally perform prediction on test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train_modified and test_modified already loaded in the workspace\n",
    "#Import module for Decision tree\n",
    "import sklearn.tree\n",
    "\n",
    "# Select three predictors 'Credit_History', 'Education', 'Gender'\n",
    "predictors =['Credit_History','Education_new','Gender_new']\n",
    "\n",
    "# Converting predictors and outcome to numpy array\n",
    "x_train = train[predictors].values\n",
    "y_train = train['Loan_Status_new_tree'].values\n",
    "\n",
    "# Model Building\n",
    "model = sklearn.tree.DecisionTreeClassifier()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Converting predictors and outcome to numpy array\n",
    "x_train = train[predictors].values\n",
    "\n",
    "#Predict Output\n",
    "predicted= model.predict(x_train)\n",
    "\n",
    "#Reverse encoding for predicted outcome\n",
    "predicted = number.inverse_transform(predicted)\n",
    "\n",
    "#Store it to test dataset\n",
    "train['Loan_Status_new_tree']=predicted\n",
    "\n",
    "#Output file to make submission\n",
    "#test_modified.to_csv(\"Submission1.csv\",columns=['Loan_ID','Loan_Status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Y    525\n",
       "N     89\n",
       "Name: Loan_Status_new_tree, dtype: int64"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Loan_Status_new_tree'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Introduction\n",
    "\n",
    "Random Forest is a versatile machine learning method capable of performing both regression and classification tasks. It also undertakes dimensional reduction methods, treats missing values, outlier values and other essential steps of data exploration, and does a fairly good job. It is a type of ensemble learning method, where a group of weak models combine to form a powerful model, read more about [Random Forest](http://www.analyticsvidhya.com/blog/2015/09/random-forest-algorithm-multiple-challenges/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import ensemble module from sklearn\n",
    "import sklearn.ensemble\n",
    "\n",
    "# Create object of RandomForestClassifier\n",
    "model=sklearn.ensemble.RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model and do prediction using Random Forest\n",
    "\n",
    "Let’s make first Random Forest model. Similar to Logistic regression and Decision Tree, here we also first select the input features, train model and finally perform prediction on test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_modified and test_modified already loaded in the workspace\n",
    "#Import module for Random Forest\n",
    "import sklearn.ensemble\n",
    "\n",
    "# Select three predictors Credit_History, Education and Gender\n",
    "predictors =['Property_Area_new','Credit_History','Married_new','Education_new','Gender_new','TotalIncome_log','LoanAmount_log']\n",
    "\n",
    "# Converting predictors and outcome to numpy array\n",
    "x_train = train[predictors].values\n",
    "y_train = train['Loan_Status_new_forest'].values\n",
    "\n",
    "# Model Building\n",
    "model = sklearn.ensemble.RandomForestClassifier()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Converting predictors and outcome to numpy array\n",
    "x_train = train[predictors].values\n",
    "\n",
    "#Predict Output\n",
    "predicted= model.predict(x_train)\n",
    "\n",
    "#Reverse encoding for predicted outcome\n",
    "predicted = number.inverse_transform(predicted)\n",
    "\n",
    "#Store it to test dataset\n",
    "train['Loan_Status_new_forest']=predicted\n",
    "\n",
    "#Output file to make submission\n",
    "#test_modified.to_csv(\"Submission1.csv\",columns=['Loan_ID','Loan_Status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Y    422\n",
       "N    192\n",
       "Name: Loan_Status_new_forest, dtype: int64"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Loan_Status_new_forest'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting important variables for model building\n",
    "\n",
    "One of the benefits of Random forest is the power of handle large data set with higher dimensionality. It can handle thousands of input variables and identify most significant variables so it is considered as one of the dimensionality reduction methods. Further, the model outputs the importance of the variables, which can be a very handy feature.\n",
    "```\n",
    "featimp = pd.Series(model.feature_importances_, index=predictors).sort_values(ascending=False)\n",
    "\n",
    "print (featimp)\n",
    "```\n",
    "I have selected all the features available in the train data set and model it using random forest:\n",
    "```\n",
    "predictors=['ApplicantIncome', 'CoapplicantIncome', 'Credit_History','Dependents', 'Education', 'Gender', 'LoanAmount',\n",
    "            'Loan_Amount_Term', 'Married', 'Property_Area', 'Self_Employed', 'TotalIncome','Log_TotalIncome']\n",
    "```\n",
    "Run feature importance command and identify Which variable has the highest impact on the model??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TotalIncome_log      0.332326\n",
      "LoanAmount_log       0.285402\n",
      "Credit_History       0.261174\n",
      "Property_Area_new    0.049834\n",
      "Married_new          0.027506\n",
      "Education_new        0.022835\n",
      "Gender_new           0.020923\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "featimp = pd.Series(model.feature_importances_, index=predictors).sort_values(ascending=False)\n",
    "\n",
    "print (featimp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 6 - Expert advice to improve model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to approach a challenge?\n",
    "\n",
    "The model development cycle goes through various stages, starting from data collection to model building. Most of us admit that data exploration needs more attention to unleashing the hidden story of data but before exploring the data to understand relationships (in variables), It’s always recommended to perform hypothesis generation. (To know more about hypothesis generation, refer to [this link](http://discuss.analyticsvidhya.com/t/why-and-when-is-hypothesis-generation-important/2109)).\n",
    "\n",
    "It is important that you spend time thinking about the given problem and gaining the domain knowledge. So, how does it help?\n",
    "\n",
    "This practice usually helps in building better features later on, which are not biased by the data available in the dataset. This is a crucial step which usually improves a model’s accuracy.\n",
    "\n",
    "At this stage, you are expected to apply structured thinking to the problem i.e. a thinking process which takes into consideration all the possible aspects of a particular problem.\n",
    "\n",
    "Which of the following has the right order of model building life cycle?\n",
    "\n",
    "**Hypothesis Generation --> Data Collection --> Data Exploration --> Model Building --> Prediction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "This step helps to extract more information from existing data. New information is extracted in terms of new features. These features may have a higher ability to explain the variance in the training data. Thus, giving improved model accuracy.\n",
    "\n",
    "Feature engineering is highly influenced by hypotheses generation. A good hypothesis results in a good feature. That’s why experts always suggest investing quality time in hypothesis generation. Feature engineering process can be divided into two steps:\n",
    "\n",
    "- Feature Transformation\n",
    "- Feature Creation\n",
    "\n",
    "Feature Transformation:\n",
    "There are various scenarios where feature transformation is required: \n",
    "* Changing the scale of a variable from original scale to scale between zero and one. \n",
    "* Some algorithms works well with normally distributed data. Therefore, we must remove skewness of variable(s). There are methods like log, square root or inverse of the values to remove skewness \n",
    "* Binning of numerical variables\n",
    "\n",
    "Feature Creation:\n",
    "Deriving new variable(s) from existing variables is known as feature creation. It helps to unleash the hidden relationship of a data set. Let’s say, we want to predict the number of transactions in a store based on transaction dates. Here transaction dates may not have a direct correlation with the number of transaction, but if we look at the day of a week, it may have a higher correlation. In this case, the information about the day of the week is hidden. We need to extract it to make the model better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "Feature Selection is a process of finding out the best subset of attributes which better explains the relationship of independent variables with target variable.\n",
    "\n",
    "You can select the useful features based on various metrics like:\n",
    "\n",
    "* Domain Knowledge: Based on domain experience, we select feature(s) which may have a higher impact on target variable.\n",
    "* Visualization: As the name suggests, it helps to visualize the relationship between variables, which makes your variable selection process easier.\n",
    "* Statistical Parameters: We also consider the p-values, information values, and other statistical metrics to select right features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to select the right value of model parameter?\n",
    "\n",
    "We know that machine learning algorithms are driven by parameters. These parameters majorly influence the outcome of the learning process.\n",
    "\n",
    "The objective of parameter tuning is to find the optimum value for each parameter to improve the accuracy of the model. To tune these parameters, you must have a good understanding of their meaning and individual impact on the model. You can repeat this process with a number of well-performing models.\n",
    "\n",
    "For example: In a random forest, we have various parameters like maxfeatures, numbertrees, randomstate, oobscore and others. Intuitive optimization of these parameter values will result in better and more accurate models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use ensemble methods to combine output of more than one models?\n",
    "\n",
    "This is the most common approach found majorly in winning solutions of Data science competitions. This technique simply combines the result of multiple weak models and produce better results. This can be achieved through many ways:\n",
    "\n",
    "- Bagging (Bootstrap Aggregating)\n",
    "- Boosting\n",
    "\n",
    "To know more about these methods, you can refer article [“Introduction to ensemble learning“](http://www.analyticsvidhya.com/blog/2015/08/introduction-ensemble-learning/).\n",
    "\n",
    "It is always a better idea to apply ensemble methods to improve the accuracy of your model. There are two good reasons for this: \n",
    "* They are generally more complex than traditional methods \n",
    "* The traditional methods give you a good base level from which you can improve and draw from to create your ensembles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validtion helps to improve your score on out of sample data set\n",
    "\n",
    "Till here, we have seen methods which can improve the accuracy of a model. But, it is not necessary that higher accuracy models always perform better (for unseen data points). Sometimes, the improvement in model’s accuracy can be due to over-fitting too.\n",
    "\n",
    "Here Cross-Validation helps to find the right answer to this question. Cross Validation says, try to leave a sample on which you do not train the model and test the model on this sample before finalizing the model. This method helps us to achieve more generalized relationships. To know more about this cross validation method, you should refer article [“Improve model performance using cross-validation“](http://www.analyticsvidhya.com/blog/2015/11/improve-model-performance-cross-validation-in-python-r/) .\n",
    "\n",
    "### Common methods used for Cross-Validation ?\n",
    "The Validation set Approach:\n",
    "In this approach, we reserve 50% of the dataset for validation and rest 50% for model training. A major disadvantage of this approach is that we train a model on 50% of the dataset only, it may be possible that we are leaving some interesting information about data i.e. higher bias.\n",
    "\n",
    "### Leave one out cross validation (LOOCV)\n",
    "In this approach, we reserve only one data-point of the available data set. And, train model on the rest of data set. This process iterates for each data point. This approach leads to higher variation in testing model effectiveness because we test against one data point. So, our estimation gets highly influenced by that one data point. If the data point turns out to be an outlier, it can lead to higher variation.\n",
    "\n",
    "### K-fold cross validation\n",
    "In this method, we follow below steps: \n",
    "* Randomly split your entire dataset into k-”folds”. \n",
    "* For each k folds in your dataset, build your model on k – 1 folds of the data set. \n",
    "* Then, test the model to check the effectiveness for kth fold and record the error you see on each of the predictions. \n",
    "* Repeat this until each of the k folds has served as the test set.\n",
    "\n",
    "The average of your k recorded errors is called the cross-validation error and will serve as your performance metric for the model.\n",
    "\n",
    "How to choose right value of k for K-fold cross validation?\n",
    "Use k=10"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
